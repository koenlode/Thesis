{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "\n",
    "import xskillscore as xs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import skill_metrics as sm\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xr.open_dataset('results_2022_ws_gcshifted_meso_gc.nc')\n",
    "synop = xr.open_dataset('synop_filtered.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistic(results, statistic_method, model_suffix='hres', variable=None, date_ranges=None, by_station=False):\n",
    "    \"\"\"\n",
    "    Calculate a statistical method (e.g., RMSE, MAE, Pearson R, Bias) between forecast and observation data.\n",
    "\n",
    "    Parameters:\n",
    "        results (xarray.Dataset): The dataset containing the forecast and observation variables.\n",
    "        statistic_method (str): The statistical method to use for the calculation.\n",
    "        model_suffix (str): The suffix used in the forecast variables to distinguish them (default is '_hres').\n",
    "        variable (str): Specific variable to analyze. If None, analyze all variables.\n",
    "        date_ranges (list of tuples): List of date ranges to filter the data. Each tuple should be (start_date, end_date).\n",
    "        by_station (bool): If True, calculate the statistic separately for each station. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        xarray.Dataset: A dataset containing the calculated statistical results.\n",
    "    \"\"\"\n",
    "    # Define supported methods, including the new 'bias' method\n",
    "    supported_methods = {\n",
    "        'rmse': lambda forecast, obs, dim: xs.rmse(forecast, obs, dim=dim, skipna=True),\n",
    "        'mae': lambda forecast, obs, dim: xs.mae(forecast, obs, dim=dim, skipna=True),\n",
    "        'mse': lambda forecast, obs, dim: xs.mse(forecast, obs, dim=dim, skipna=True),\n",
    "        'pearson_r': lambda forecast, obs, dim: xs.pearson_r(forecast, obs, dim=dim, skipna=True),\n",
    "        'spearman_r': lambda forecast, obs, dim: xs.spearman_r(forecast, obs, dim=dim, skipna=True),\n",
    "        'bias': lambda forecast, obs, dim: (forecast - obs).mean(dim=dim, skipna=True),  # Bias calculation\n",
    "        'mean_absolute_percentage_error': lambda forecast, obs, dim: xs.mape(forecast, obs, dim=dim, skipna=True),\n",
    "        'brier_score': lambda forecast, obs, dim: xs.brier_score(forecast, obs, dim=dim, skipna=True),\n",
    "        'threshold_brier_score': lambda forecast, obs, dim: xs.threshold_brier_score(forecast, obs, dim=dim, skipna=True),\n",
    "        'crps_gaussian': lambda forecast, obs, dim: xs.crps_gaussian(forecast, obs, dim=dim, skipna=True),\n",
    "        'crps_quadrature': lambda forecast, obs, dim: xs.crps_quadrature(forecast, obs, dim=dim, skipna=True),\n",
    "        'crps_ensemble': lambda forecast, obs, dim: xs.crps_ensemble(forecast, obs, dim=dim, skipna=True),\n",
    "        'rank_histogram': lambda forecast, obs, dim: xs.rank_histogram(forecast, obs, dim=dim, skipna=True),\n",
    "        'roc': lambda forecast, obs, dim: xs.roc(forecast, obs, dim=dim, skipna=True),\n",
    "        'reliability': lambda forecast, obs, dim: xs.reliability(forecast, obs, dim=dim, skipna=True),\n",
    "        'discrimination': lambda forecast, obs, dim: xs.discrimination(forecast, obs, dim=dim, skipna=True),\n",
    "        'rps': lambda forecast, obs, dim: xs.rps(forecast, obs, dim=dim, skipna=True)\n",
    "    }\n",
    "\n",
    "    # Check if the method is supported\n",
    "    if statistic_method not in supported_methods:\n",
    "        raise ValueError(f\"Statistic method '{statistic_method}' is not supported. Choose from {list(supported_methods.keys())}.\")\n",
    "\n",
    "    # If date ranges are provided, filter the data accordingly\n",
    "    if date_ranges:\n",
    "        datasets = [results.sel(time=slice(start_date, end_date)) for start_date, end_date in date_ranges]\n",
    "        results = xr.concat(datasets, dim='time')\n",
    "\n",
    "    # Define the variables to compare (forecast vs observation)\n",
    "    variables = {\n",
    "        f'2m_temperature_{model_suffix}': '2m_temperature_synop',\n",
    "        f'mean_sea_level_pressure_{model_suffix}': 'mean_sea_level_pressure_synop',\n",
    "        f'10m_v_component_of_wind_{model_suffix}': '10m_v_component_of_wind_synop',\n",
    "        f'10m_u_component_of_wind_{model_suffix}': '10m_u_component_of_wind_synop',\n",
    "        f'total_precipitation_6hr_{model_suffix}': 'total_precipitation_6hr_synop',\n",
    "        # add a new variable for wind speed\n",
    "        f'10m_wind_speed_{model_suffix}': '10m_wind_speed_synop'\n",
    "    }\n",
    "    \n",
    "\n",
    "    if variable:\n",
    "        variables = {f'{variable}_{model_suffix}': f'{variable}_synop'}\n",
    "\n",
    "    # Determine the dimensions to calculate over\n",
    "    dims = ['time']\n",
    "    if not by_station:\n",
    "        dims.append('station')\n",
    "\n",
    "    # Apply the selected statistic method to each variable\n",
    "    results = xr.Dataset({\n",
    "        forecast_var: supported_methods[statistic_method](results[forecast_var], results[obs_var], dim=dims)\n",
    "        for forecast_var, obs_var in variables.items()\n",
    "    })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def calculate_all_statistics(results_chunked, metrics, models, by_station=False):\n",
    "    \"\"\"\n",
    "    Calculates statistical metrics for different models and variables.\n",
    "\n",
    "    Parameters:\n",
    "    - results_chunked: The dataset or collection of results to be analyzed. This is typically a large\n",
    "      dataset split into chunks.\n",
    "    - metrics: A list of statistical metrics to be calculated (e.g., ['rmse', 'mae']).\n",
    "    - models: A list of models or variables for which the metrics are calculated (e.g., ['hres', 'gc', 'analysis', 'meso']).\n",
    "\n",
    "    Returns:\n",
    "    - statistics: A dictionary where each key is a combination of a metric and a model\n",
    "      (e.g., 'rmse_hres', 'mae_gc') and the value is the computed statistic for that combination.\n",
    "    \"\"\"\n",
    "    statistics = {}\n",
    "    for metric in metrics:\n",
    "        for model in models:\n",
    "            key = f\"{metric}_{model}\"\n",
    "            statistics[key] = calculate_statistic(\n",
    "                results_chunked, \n",
    "                metric, \n",
    "                model, \n",
    "                by_station=by_station\n",
    "            )\n",
    "    return statistics\n",
    "\n",
    "def plot_statistic_results(statistics, error_metric, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots the statistical results for predefined variables against forecast lead time for one or multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "        error_metric (str): The error metric to plot (e.g., 'rmse', 'mse', 'mae').\n",
    "        save_path (str, optional): The file path to save the plot. If None, the plot will be displayed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure that the error_metric is matched as a prefix in the keys\n",
    "    datasets = [statistics[key] for key in statistics.keys() if key.startswith(error_metric + \"_\")]\n",
    "\n",
    "    if len(datasets) == 0:\n",
    "        raise ValueError(f\"No dataset matches the error metric: {error_metric}\")\n",
    "    \n",
    "    # Check if each dataset is an xarray Dataset\n",
    "    for i, ds in enumerate(datasets):\n",
    "        if not hasattr(ds, 'data_vars'):\n",
    "            raise TypeError(f\"Dataset {i+1} is not an xarray.Dataset. Ensure you pass the dataset object, not its name as a string.\")\n",
    "    \n",
    "    # Define variable names and their corresponding units\n",
    "    variables = {\n",
    "        '2m_temperature': '°C',\n",
    "        'mean_sea_level_pressure': 'hPa',\n",
    "        '10m_v_component_of_wind': 'm/s',\n",
    "        '10m_u_component_of_wind': 'm/s',\n",
    "        'total_precipitation_6hr': 'mm',\n",
    "        '10m_wind_speed': 'm/s'\n",
    "    }\n",
    "    \n",
    "    # Convert lead times to numeric values (hours) for plotting\n",
    "    lead_times_numeric_list = [ds['prediction_timedelta'].dt.total_seconds() / 3600 for ds in datasets]\n",
    "    \n",
    "    # Ensure lead times match between datasets if there are multiple\n",
    "    if len(datasets) > 1:\n",
    "        for i in range(1, len(lead_times_numeric_list)):\n",
    "            if not lead_times_numeric_list[i].equals(lead_times_numeric_list[0]):\n",
    "                raise ValueError(\"Lead times in the datasets do not match.\")\n",
    "    \n",
    "    # Extract base variable names and model suffixes\n",
    "    def extract_base_variable_name(var_name):\n",
    "        match = re.match(r'^(.*)_(.+)$', var_name)\n",
    "        if match:\n",
    "            return match.groups()\n",
    "        else:\n",
    "            return var_name, None\n",
    "    \n",
    "    variables_dict_list = []\n",
    "    for ds in datasets:\n",
    "        variables_dict = {extract_base_variable_name(var)[0]: var for var in ds.data_vars}\n",
    "        variables_dict_list.append(variables_dict)\n",
    "    \n",
    "    # Initialize the figure and subplots\n",
    "    fig, axs = plt.subplots(len(variables), 1, figsize=(10, 3 * len(variables)))\n",
    "\n",
    "    if len(variables) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    # Define line styles\n",
    "    line_styles = ['--', '-.', ':', '-']\n",
    "    \n",
    "    # Loop through variables to plot\n",
    "    for i, (base_var, unit) in enumerate(variables.items()):\n",
    "        for j, (ds, variables_dict) in enumerate(zip(datasets, variables_dict_list)):\n",
    "            if base_var in variables_dict:\n",
    "                var = variables_dict[base_var]\n",
    "                _, model_suffix = extract_base_variable_name(var)\n",
    "                label = model_suffix if len(datasets) > 1 else 'Observation'\n",
    "                axs[i].plot(lead_times_numeric_list[j], ds[var], marker='o', linestyle=line_styles[j % len(line_styles)], \n",
    "                            alpha=0.75, linewidth=1.25, label=label)\n",
    "        \n",
    "        axs[i].set_title(f'{base_var.replace(\"_\", \" \").title()} vs Observation', fontsize=14)\n",
    "        axs[i].set_xlabel('Lead Time (hours)', fontsize=12)\n",
    "        axs[i].set_ylabel(f'{error_metric.upper()} ({unit})', fontsize=12)\n",
    "        axs[i].grid(True, linestyle='--', linewidth=0.5)\n",
    "        axs[i].set_xticks(range(0, int(max(lead_times_numeric_list[0])) + 1, 6))\n",
    "\n",
    "        if len(datasets) > 1:\n",
    "            axs[i].legend(loc='center left', bbox_to_anchor=(1,0.8), fontsize=10, frameon=False)\n",
    "\n",
    "        if ds[var].min() >= 0:\n",
    "            axs[i].set_ylim(bottom=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_statistics_for_variable(statistics, variable, metrics=['rmse', 'mae', 'mse', 'bias'], save_path=None):\n",
    "    \"\"\"\n",
    "    Plots multiple statistical metrics (e.g., rmse, mae, mse, bias) for a single variable\n",
    "    across different models and metrics, with units displayed on the vertical axis.\n",
    "\n",
    "    Parameters:\n",
    "        statistics (dict): A dictionary containing datasets with metric-model combinations as keys.\n",
    "        variable (str): The variable to plot (e.g., '2m_temperature').\n",
    "        save_path (str, optional): The file path to save the plot. If None, the plot will be displayed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_units = {\n",
    "        '2m_temperature': '°C',\n",
    "        'mean_sea_level_pressure': 'hPa',\n",
    "        '10m_v_component_of_wind': 'm/s',\n",
    "        '10m_u_component_of_wind': 'm/s',\n",
    "        'total_precipitation_6hr': 'mm',\n",
    "        '10m_wind_speed': 'm/s'\n",
    "    }\n",
    "    \n",
    "    unit = variable_units.get(variable, '')  # Get unit for the variable\n",
    "    \n",
    "    metric_model_combinations = [key for key in statistics.keys() if any(metric in key for metric in metrics)]\n",
    "    \n",
    "    fig, axs = plt.subplots(len(metrics), 1, figsize=(10, 3 * len(metrics)))\n",
    "\n",
    "    if len(metrics) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    line_styles = ['--', '-.', ':', '-']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, key in enumerate(metric_model_combinations):\n",
    "            if key.startswith(metric):\n",
    "                ds = statistics[key]\n",
    "                model_suffix = key.split(\"_\")[1]\n",
    "                variable_key = f'{variable}_{model_suffix}'\n",
    "\n",
    "                if variable_key in ds.data_vars:\n",
    "                    lead_times = ds['prediction_timedelta'].dt.total_seconds() / 3600\n",
    "                    var_data = ds[variable_key]\n",
    "                    axs[i].plot(lead_times, var_data, marker='o', linestyle=line_styles[j % len(line_styles)], \n",
    "                                alpha=0.75, linewidth=1.25, label=model_suffix)\n",
    "        \n",
    "        axs[i].set_title(f'{metric.upper()} for {variable.replace(\"_\", \" \").title()}', fontsize=14)\n",
    "        axs[i].set_xlabel('Lead Time (hours)', fontsize=12)\n",
    "        axs[i].set_ylabel(f'{metric.upper()} ({unit})', fontsize=12)\n",
    "        axs[i].grid(True, linestyle='--', linewidth=0.5)\n",
    "        axs[i].set_xticks(range(0, int(max(lead_times)) + 1, 6))\n",
    "        \n",
    "        if var_data.min() >= 0:\n",
    "            axs[i].set_ylim(bottom=0)\n",
    "\n",
    "        axs[i].legend(loc='center left', bbox_to_anchor=(1, 0.8), fontsize=10, frameon=False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map creation and spatial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stations_with_metric(synop_data, metric_dict=None, metric_label=None, variable_name=None, marker_size=50, save_path=None):\n",
    "    \"\"\"\n",
    "    Function to plot weather stations and color them based on a given metric for 4 different models.\n",
    "    \n",
    "    Parameters:\n",
    "    - synop_data (xarray.Dataset): Dataset containing the station data with latitude, longitude, and station name.\n",
    "    - metric_dict (dict): Dictionary with keys as model names and values as metrics to be plotted for each model.\n",
    "    - metric_label (str, optional): Label for the color bar, describing the metric. Default is None.\n",
    "    - variable_name (str, optional): Name of the weather variable. Default is None.\n",
    "    - marker_size (int, optional): Size of the station markers. Default is 50.\n",
    "    - save_path (str, optional): Path to save the figure. Default is None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the models you want to plot\n",
    "    model_suffix = ['gc', 'meso', 'hres', 'analysis']\n",
    "\n",
    "    # Extract station information\n",
    "    station_lats = synop_data['lat'].isel(time=100).values\n",
    "    station_lons = synop_data['lon'].isel(time=100).values\n",
    "    station_names = synop_data['station'].values\n",
    "\n",
    "    # Remove invalid lat/lon stations\n",
    "    valid_mask = ~np.isnan(station_lats) & ~np.isnan(station_lons)\n",
    "    station_lats = station_lats[valid_mask]\n",
    "    station_lons = station_lons[valid_mask]\n",
    "    station_names = station_names[valid_mask]\n",
    "\n",
    "    # Define the latitude and longitude boundaries\n",
    "    lat_min, lat_max = 40, 70\n",
    "    lon_min, lon_max = -5, 16\n",
    "\n",
    "    # Filter based on lat/lon boundaries\n",
    "    valid_bounds_mask = (\n",
    "        (station_lats >= lat_min) & (station_lats <= lat_max) &\n",
    "        (station_lons >= lon_min) & (station_lons <= lon_max)\n",
    "    )\n",
    "    station_lats = station_lats[valid_bounds_mask]\n",
    "    station_lons = station_lons[valid_bounds_mask]\n",
    "    station_names = station_names[valid_bounds_mask]\n",
    "\n",
    "    # Create a GeoDataFrame for the stations\n",
    "    gdf_stations = gpd.GeoDataFrame(\n",
    "        {'Station': station_names},\n",
    "        geometry=[Point(lon, lat) for lon, lat in zip(station_lons, station_lats)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Load shapefiles for the Netherlands and provinces\n",
    "    world = gpd.read_file(\"/home/koenr/thesis_code/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp\")\n",
    "    netherlands = world[(world.SOVEREIGNT == \"Netherlands\") & (world.CONTINENT == \"Europe\")].to_crs(epsg=28992)\n",
    "    \n",
    "    provinces = gpd.read_file(\"/home/koenr/thesis_code/ne_10m_admin_1_states_provinces/ne_10m_admin_1_states_provinces.shp\")\n",
    "    netherlands_provinces = provinces[provinces['adm1_code'].str.startswith('NLD')].to_crs(epsg=28992)\n",
    "\n",
    "    # Reproject stations to EPSG:28992\n",
    "    gdf_stations = gdf_stations.to_crs(epsg=28992)\n",
    "\n",
    "    # Calculate global min and max for consistent colorbar scaling across all models\n",
    "    all_metrics = np.concatenate([metric_dict[model] for model in model_suffix if metric_dict.get(model) is not None])\n",
    "    vmin, vmax = np.nanmin(all_metrics), np.nanmax(all_metrics)\n",
    "\n",
    "    # Define colormap preferences based on error type\n",
    "    if metric_label in ['rmse', 'mae']:\n",
    "        color_map = 'magma'  # Choose a sequential colormap for error magnitude\n",
    "        norm = None\n",
    "    elif metric_label == 'bias':\n",
    "        color_map = 'seismic'  # Diverging colormap centered at zero\n",
    "        norm = TwoSlopeNorm(vmin=-max(abs(vmin), abs(vmax)), vcenter=0, vmax=max(abs(vmin), abs(vmax)))\n",
    "    else:\n",
    "        color_map = 'viridis'  # Default colormap\n",
    "        norm = None\n",
    "\n",
    "    # Create 4 subplots for the 4 models\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, model in enumerate(model_suffix):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Use the corresponding metric for each model\n",
    "        metric = metric_dict.get(model, None)\n",
    "\n",
    "        # Update GeoDataFrame with metric\n",
    "        gdf_stations['Metric'] = metric if metric is not None else np.nan\n",
    "\n",
    "        # Plot the Netherlands with province boundaries\n",
    "        netherlands.plot(ax=ax, color='white', edgecolor='black', linewidth=0.5)\n",
    "        netherlands_provinces.plot(ax=ax, color='none', edgecolor='blue', linewidth=0.25)\n",
    "\n",
    "        # Plot the stations with color based on the metric\n",
    "        if metric is not None:\n",
    "            gdf_stations.plot(ax=ax, column='Metric', cmap=color_map, marker='^', markersize=marker_size, legend=True, vmin=vmin, vmax=vmax, norm=norm)\n",
    "        else:\n",
    "            gdf_stations.plot(ax=ax, color='green', marker='^', markersize=marker_size, label='Weather Stations')\n",
    "\n",
    "        # Annotate the stations\n",
    "        for idx, row in gdf_stations.iterrows():\n",
    "            ax.annotate(row[\"Station\"], xy=(row.geometry.x, row.geometry.y),\n",
    "                        xytext=(3, 3), textcoords=\"offset points\", fontsize=6)\n",
    "\n",
    "        # Set plot limits and remove axes\n",
    "        padding = 15000\n",
    "        bounds = gdf_stations.total_bounds\n",
    "        ax.set_xlim(bounds[0] - padding, bounds[2] + padding)\n",
    "        ax.set_ylim(bounds[1] - padding - 5000, bounds[3] + padding)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        # Set the title for each subplot\n",
    "        ax.set_title(f\"{model.upper()}\")\n",
    "\n",
    "    # Add a main title with padding above the plots\n",
    "    plt.suptitle(f\"{variable_name} {metric_label} per Weather Station\", x=0.56, fontsize=16)\n",
    "    \n",
    "    # Adjust layout to prevent overlap and leave space for suptitle\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure if a path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Print the path where the plot is saved\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to map_plots_shifted/map_2m_temperature_rmse.png\n",
      "Plot saved to map_plots_shifted/map_2m_temperature_mae.png\n",
      "Plot saved to map_plots_shifted/map_2m_temperature_bias.png\n",
      "Plot saved to map_plots_shifted/map_mean_sea_level_pressure_rmse.png\n",
      "Plot saved to map_plots_shifted/map_mean_sea_level_pressure_mae.png\n",
      "Plot saved to map_plots_shifted/map_mean_sea_level_pressure_bias.png\n",
      "Plot saved to map_plots_shifted/map_10m_wind_speed_rmse.png\n",
      "Plot saved to map_plots_shifted/map_10m_wind_speed_mae.png\n",
      "Plot saved to map_plots_shifted/map_10m_wind_speed_bias.png\n",
      "Plot saved to map_plots_shifted/map_10m_u_component_of_wind_rmse.png\n",
      "Plot saved to map_plots_shifted/map_10m_u_component_of_wind_mae.png\n",
      "Plot saved to map_plots_shifted/map_10m_u_component_of_wind_bias.png\n",
      "Plot saved to map_plots_shifted/map_10m_v_component_of_wind_rmse.png\n",
      "Plot saved to map_plots_shifted/map_10m_v_component_of_wind_mae.png\n",
      "Plot saved to map_plots_shifted/map_10m_v_component_of_wind_bias.png\n",
      "Plot saved to map_plots_shifted/map_total_precipitation_6hr_rmse.png\n",
      "Plot saved to map_plots_shifted/map_total_precipitation_6hr_mae.png\n",
      "Plot saved to map_plots_shifted/map_total_precipitation_6hr_bias.png\n"
     ]
    }
   ],
   "source": [
    "model_suffix = ['gc', 'meso', 'hres', 'analysis']\n",
    "\n",
    "variables = [\n",
    "                '2m_temperature', \n",
    "                'mean_sea_level_pressure',\n",
    "                '10m_wind_speed', \n",
    "                '10m_u_component_of_wind', \n",
    "                '10m_v_component_of_wind', \n",
    "                'total_precipitation_6hr',\n",
    "             ]\n",
    "\n",
    "metrics = ['rmse', 'mae', 'bias']\n",
    "\n",
    "for variable in variables:\n",
    "    for metric in metrics:\n",
    "        # Initialize dictionary to store results for the current metric\n",
    "        metric_values = {}\n",
    "        \n",
    "        for model in model_suffix:\n",
    "            # Dynamically pass the metric into the calculation\n",
    "            stat_result = calculate_statistic(results, metric, model, by_station=True).mean('prediction_timedelta').compute()\n",
    "            \n",
    "            # Store the result for the current model and variable\n",
    "            metric_values[model] = stat_result[f'{variable}_{model}']\n",
    "\n",
    "        # Define the save path for the plot\n",
    "        save_path = f'map_plots_shifted/map_{variable}_{metric}.png'\n",
    "\n",
    "        # Call the updated plotting function\n",
    "        plot_stations_with_metric(synop, metric_dict=metric_values, variable_name=variable, metric_label=f'{metric}', save_path=save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
